"""
AICE Associate ìê²©ì¸ì¦ ë²”ìš© ì±„ì  ëª¨ë“ˆ
- ë¬¸ì œì§‘ í•˜ë‹¨ì—ì„œ aice_ans.grade_answers(globals())ë¡œ í˜¸ì¶œ
- aice_ans.pyì™€ ê°™ì€ í´ë”ì— answer_config.json íŒŒì¼ì´ ìˆì–´ì•¼ í•¨
"""

import json
import os
from typing import Any, Dict, Optional, Tuple


# ì´ ëª¨ë“ˆ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
# êµ¬ê¸€ ì½”ë©ì—ì„œ aice_ans.pyì™€ answer_config.jsonì„ ê°™ì€ í´ë”ì— ì—…ë¡œë“œí•˜ë©´
# ìë™ìœ¼ë¡œ ê°™ì€ í´ë”ì—ì„œ ì„¤ì • íŒŒì¼ì„ ì°¾ìŒ
MODULE_DIR = os.path.dirname(os.path.abspath(__file__))


def load_config(config_path: Optional[str] = None) -> Dict:
    """
    ì„¤ì • íŒŒì¼ ë¡œë“œ
    - config_pathê°€ Noneì´ë©´ ëª¨ë“ˆê³¼ ê°™ì€ í´ë”ì—ì„œ answer_config.jsonì„ ì°¾ìŒ
    - config_pathê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ê²½ë¡œì—ì„œ ë¡œë“œ
    """
    if config_path is None:
        config_path = os.path.join(MODULE_DIR, "answer_config.json")

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def check_exact_number(answer: Any, expected: Any, tolerance: float = 0) -> Tuple[bool, str]:
    """ìˆ«ì ì •í™•íˆ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸ (í—ˆìš© ì˜¤ì°¨ ì§€ì›)"""
    try:
        answer_val = float(answer)
        expected_val = float(expected)

        if tolerance == 0:
            is_correct = answer_val == expected_val
        else:
            is_correct = abs(answer_val - expected_val) <= tolerance

        if is_correct:
            return True, "ì •ë‹µì…ë‹ˆë‹¤!"
        else:
            return False, f"ì˜¤ë‹µì…ë‹ˆë‹¤. {answer} != {expected}"
    except (TypeError, ValueError) as e:
        return False, f"ìˆ«ì í˜•ì‹ ì˜¤ë¥˜: {e}"


def check_exact_string(answer: Any, expected: str, case_sensitive: bool = True) -> Tuple[bool, str]:
    """ë¬¸ìì—´ ì •í™•íˆ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸"""
    try:
        answer_str = str(answer)
        expected_str = str(expected)

        if case_sensitive:
            is_correct = answer_str == expected_str
        else:
            is_correct = answer_str.lower() == expected_str.lower()

        if is_correct:
            return True, "ì •ë‹µì…ë‹ˆë‹¤!"
        else:
            return False, f"ì˜¤ë‹µì…ë‹ˆë‹¤. '{answer}' != '{expected}'"
    except Exception as e:
        return False, f"ë¬¸ìì—´ ë¹„êµ ì˜¤ë¥˜: {e}"


def check_number_range(answer: Any, min_val: Optional[float] = None,
                       max_val: Optional[float] = None) -> Tuple[bool, str]:
    """ìˆ«ì ë²”ìœ„ ê²€ì¦"""
    try:
        answer_val = float(answer)

        if min_val is not None and answer_val < min_val:
            return False, f"ì˜¤ë‹µì…ë‹ˆë‹¤. {answer_val}ì€(ëŠ”) ìµœì†Œê°’ {min_val}ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤."

        if max_val is not None and answer_val > max_val:
            return False, f"ì˜¤ë‹µì…ë‹ˆë‹¤. {answer_val}ì€(ëŠ”) ìµœëŒ€ê°’ {max_val}ë³´ë‹¤ í½ë‹ˆë‹¤."

        return True, f"ì •ë‹µì…ë‹ˆë‹¤! (ê°’: {answer_val})"
    except (TypeError, ValueError) as e:
        return False, f"ìˆ«ì í˜•ì‹ ì˜¤ë¥˜: {e}"


def check_history(history_dict: Any, requirements: Dict) -> Tuple[bool, str]:
    """ë”¥ëŸ¬ë‹ í•™ìŠµ history ë¶„ì„ ë° ê²€ì¦

    requirements:
        - max_epochs: ìµœëŒ€ ì—í­ ìˆ˜
        - patience: EarlyStopping patience ê°’
        - monitor: ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ (ì˜ˆ: 'val_accuracy', 'val_mae')
        - monitor_mode: 'max' ë˜ëŠ” 'min' (accuracyëŠ” max, loss/maeëŠ” min)
    """
    try:
        if not isinstance(history_dict, dict):
            return False, "history.historyê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤."

        max_epochs = requirements.get('max_epochs', 30)
        patience = requirements.get('patience', 3)
        monitor = requirements.get('monitor', 'val_accuracy')
        monitor_mode = requirements.get('monitor_mode', 'max')

        # ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ ì¡´ì¬ í™•ì¸
        if monitor not in history_dict:
            return False, f"ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ '{monitor}'ê°€ historyì— ì—†ìŠµë‹ˆë‹¤."

        monitor_values = history_dict[monitor]
        actual_epochs = len(monitor_values)

        # ëª¨ë“  ì—í­ì„ ì†Œì§„í•œ ê²½ìš°: patience ê²€ì¦ ìƒëµ
        if actual_epochs >= max_epochs:
            return True, f"ì •ë‹µì…ë‹ˆë‹¤! (ì „ì²´ {actual_epochs} ì—í­ í•™ìŠµ ì™„ë£Œ)"

        # EarlyStoppingì´ ì‘ë™í•œ ê²½ìš°: patience ê²€ì¦
        if monitor_mode == 'max':
            best_value = max(monitor_values)
            best_epoch = monitor_values.index(best_value)
        else:  # min
            best_value = min(monitor_values)
            best_epoch = monitor_values.index(best_value)

        expected_stop_epoch = best_epoch + patience + 1  # 0-indexed + patience + 1

        # patience ê²€ì¦: best_epoch ì´í›„ patience ì—í­ ë™ì•ˆ ê°œì„ ì´ ì—†ì—ˆëŠ”ì§€ í™•ì¸
        # ë˜ëŠ” best_valueì™€ ë™ì¼í•œ ê°’ì´ ì´í›„ì— ìˆëŠ” ê²½ìš°ë„ í—ˆìš©
        if actual_epochs == expected_stop_epoch:
            return True, f"ì •ë‹µì…ë‹ˆë‹¤! (EarlyStopping ì •ìƒ ì‘ë™, best epoch: {best_epoch + 1})"

        # ë™ì ì¸ ê²½ìš° ì²´í¬
        if monitor_mode == 'max':
            best_indices = [i for i, v in enumerate(monitor_values) if v == best_value]
        else:
            best_indices = [i for i, v in enumerate(monitor_values) if v == best_value]

        for idx in best_indices:
            if actual_epochs == idx + patience + 1:
                return True, f"ì •ë‹µì…ë‹ˆë‹¤! (EarlyStopping ì •ìƒ ì‘ë™, best epoch: {idx + 1})"

        return False, f"EarlyStopping patience ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‹¤ì œ ì—í­: {actual_epochs}, ì˜ˆìƒ: {expected_stop_epoch})"

    except Exception as e:
        return False, f"history ê²€ì¦ ì˜¤ë¥˜: {e}"


def check_figure(fig: Any, requirements: Dict) -> Tuple[bool, str]:
    """matplotlib figure êµ¬ì¡° ê²€ì¦

    requirements:
        - num_axes: í•„ìš”í•œ axes ê°œìˆ˜
        - lines_per_ax: ê° axë‹¹ í•„ìš”í•œ ë¼ì¸ ìˆ˜ (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ ê°’)
        - titles: ê° axì˜ ì œëª© ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        - xlabels: ê° axì˜ xì¶• ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        - ylabels: ê° axì˜ yì¶• ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
    """
    try:
        # matplotlib.figure.Figure íƒ€ì… ì²´í¬
        fig_type = type(fig).__name__
        if 'Figure' not in fig_type:
            return False, f"figê°€ matplotlib Figure ê°ì²´ê°€ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {fig_type})"

        axes = fig.axes
        num_axes = requirements.get('num_axes', 2)

        # axes ê°œìˆ˜ í™•ì¸
        if len(axes) != num_axes:
            return False, f"axes ê°œìˆ˜ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‹¤ì œ: {len(axes)}, í•„ìš”: {num_axes})"

        # ê° axì˜ ë¼ì¸ ìˆ˜ í™•ì¸
        lines_per_ax = requirements.get('lines_per_ax', 2)
        if isinstance(lines_per_ax, int):
            lines_per_ax = [lines_per_ax] * num_axes

        for i, ax in enumerate(axes):
            lines = ax.get_lines()
            if len(lines) < lines_per_ax[i]:
                return False, f"ax[{i}]ì˜ ë¼ì¸ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì‹¤ì œ: {len(lines)}, í•„ìš”: {lines_per_ax[i]})"

        # ì œëª© í™•ì¸ (ì„ íƒ)
        titles = requirements.get('titles')
        if titles:
            for i, ax in enumerate(axes):
                actual_title = ax.get_title()
                if actual_title != titles[i]:
                    return False, f"ax[{i}]ì˜ ì œëª©ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‹¤ì œ: '{actual_title}', í•„ìš”: '{titles[i]}')"

        # xì¶• ë ˆì´ë¸” í™•ì¸ (ì„ íƒ)
        xlabels = requirements.get('xlabels')
        if xlabels:
            for i, ax in enumerate(axes):
                actual_xlabel = ax.get_xlabel()
                if actual_xlabel != xlabels[i]:
                    return False, f"ax[{i}]ì˜ xì¶• ë ˆì´ë¸”ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‹¤ì œ: '{actual_xlabel}', í•„ìš”: '{xlabels[i]}')"

        # yì¶• ë ˆì´ë¸” í™•ì¸ (ì„ íƒ)
        ylabels = requirements.get('ylabels')
        if ylabels:
            for i, ax in enumerate(axes):
                actual_ylabel = ax.get_ylabel()
                if actual_ylabel != ylabels[i]:
                    return False, f"ax[{i}]ì˜ yì¶• ë ˆì´ë¸”ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‹¤ì œ: '{actual_ylabel}', í•„ìš”: '{ylabels[i]}')"

        return True, "ì •ë‹µì…ë‹ˆë‹¤!"

    except Exception as e:
        return False, f"figure ê²€ì¦ ì˜¤ë¥˜: {e}"


def check_confusion_matrix(cm: Any, requirements: Dict) -> Tuple[bool, str]:
    """sklearn confusion_matrix ê²°ê³¼ ê²€ì¦

    requirements:
        - num_classes: ì˜ˆìƒ í´ë˜ìŠ¤ ê°œìˆ˜ (ì„ íƒ)
    """
    try:
        # numpy ndarray íƒ€ì… ì²´í¬
        type_name = type(cm).__name__
        if 'ndarray' not in type_name:
            return False, f"numpy ndarrayê°€ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {type_name})"

        # 2D ë°°ì—´ í™•ì¸
        if len(cm.shape) != 2:
            return False, f"2D ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤. (shape: {cm.shape})"

        # ì •ë°©í–‰ë ¬ í™•ì¸
        if cm.shape[0] != cm.shape[1]:
            return False, f"ì •ë°©í–‰ë ¬ì´ ì•„ë‹™ë‹ˆë‹¤. (shape: {cm.shape})"

        # í´ë˜ìŠ¤ ê°œìˆ˜ í™•ì¸ (ì„ íƒ)
        num_classes = requirements.get('num_classes')
        if num_classes and cm.shape[0] != num_classes:
            return False, f"í´ë˜ìŠ¤ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ì‹¤ì œ: {cm.shape[0]}, í•„ìš”: {num_classes})"

        return True, f"ì •ë‹µì…ë‹ˆë‹¤! ({cm.shape[0]}x{cm.shape[1]} confusion matrix)"

    except Exception as e:
        return False, f"confusion_matrix ê²€ì¦ ì˜¤ë¥˜: {e}"


def check_classification_report(report: Any, requirements: Dict) -> Tuple[bool, str]:
    """sklearn classification_report(output_dict=True) ê²°ê³¼ ê²€ì¦

    requirements:
        - num_classes: ì˜ˆìƒ í´ë˜ìŠ¤ ê°œìˆ˜ (ì„ íƒ)
    """
    try:
        # dict íƒ€ì… í™•ì¸
        if not isinstance(report, dict):
            return False, f"dict íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {type(report).__name__})"

        # í•„ìˆ˜ ë©”íƒ€ í‚¤ ì¡´ì¬ í™•ì¸
        meta_keys = ['accuracy', 'macro avg', 'weighted avg']
        missing_keys = [k for k in meta_keys if k not in report]
        if missing_keys:
            return False, f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {missing_keys}"

        # accuracy ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸
        if not isinstance(report['accuracy'], (int, float)):
            return False, f"'accuracy' ê°’ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {type(report['accuracy']).__name__})"

        # macro avg, weighted avgê°€ dictì¸ì§€ í™•ì¸
        for key in ['macro avg', 'weighted avg']:
            if not isinstance(report[key], dict):
                return False, f"'{key}'ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {type(report[key]).__name__})"

        # í´ë˜ìŠ¤ ê°œìˆ˜ í™•ì¸ (ì„ íƒ)
        num_classes = requirements.get('num_classes')
        if num_classes:
            class_keys = [k for k in report.keys() if k not in meta_keys]
            if len(class_keys) != num_classes:
                return False, f"í´ë˜ìŠ¤ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ì‹¤ì œ: {len(class_keys)}, í•„ìš”: {num_classes})"

        # í´ë˜ìŠ¤ í‚¤ ê°œìˆ˜ ê³„ì‚°
        class_keys = [k for k in report.keys() if k not in meta_keys]
        return True, f"ì •ë‹µì…ë‹ˆë‹¤! ({len(class_keys)}ê°œ í´ë˜ìŠ¤ classification report)"

    except Exception as e:
        return False, f"classification_report ê²€ì¦ ì˜¤ë¥˜: {e}"


def check_keras_model(model: Any, requirements: Dict) -> Tuple[bool, str]:
    """Keras ëª¨ë¸ êµ¬ì¡° ê²€ì¦

    requirements:
        - min_dense_layers: ìµœì†Œ Dense ë ˆì´ì–´ ìˆ˜ (ì¶œë ¥ì¸µ ì œì™¸)
        - min_dropout_layers: ìµœì†Œ Dropout ë ˆì´ì–´ ìˆ˜
        - dropout_rate: Dropout ë¹„ìœ¨ (í—ˆìš© ì˜¤ì°¨ 0.01)
        - hidden_activation: íˆë“  ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ (ì˜ˆ: 'relu', 'gelu')
        - output_activation: ì¶œë ¥ ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ (ì˜ˆ: 'sigmoid', 'softmax', None)
    """
    try:
        # Keras ëª¨ë¸ íƒ€ì… ì²´í¬
        model_type = type(model).__name__
        model_module = type(model).__module__

        if 'keras' not in model_module.lower() and 'Sequential' not in model_type and 'Model' not in model_type:
            return False, f"Keras ëª¨ë¸ì´ ì•„ë‹™ë‹ˆë‹¤. (íƒ€ì…: {model_type})"

        # ëª¨ë¸ ë ˆì´ì–´ ê°€ì ¸ì˜¤ê¸°
        try:
            layers = model.layers
        except AttributeError:
            return False, "ëª¨ë¸ì—ì„œ ë ˆì´ì–´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë ˆì´ì–´ ë¶„ë¥˜
        dense_layers = []
        dropout_layers = []

        for layer in layers:
            layer_class = type(layer).__name__

            if 'Dense' in layer_class:
                dense_layers.append(layer)
            elif 'Dropout' in layer_class:
                dropout_layers.append(layer)

        # ì¶œë ¥ì¸µ ë¶„ë¦¬ (ë§ˆì§€ë§‰ Dense ë ˆì´ì–´)
        if dense_layers:
            output_layer = dense_layers[-1]
            hidden_dense_layers = dense_layers[:-1]
        else:
            return False, "Dense ë ˆì´ì–´ê°€ ì—†ìŠµë‹ˆë‹¤."

        errors = []

        # 1. ìµœì†Œ Dense ë ˆì´ì–´ ìˆ˜ ê²€ì‚¬ (íˆë“  ë ˆì´ì–´ë§Œ)
        min_dense = requirements.get('min_dense_layers', 0)
        if min_dense > 0 and len(hidden_dense_layers) < min_dense:
            errors.append(f"íˆë“  Dense ë ˆì´ì–´ ë¶€ì¡± (ì‹¤ì œ: {len(hidden_dense_layers)}, í•„ìš”: {min_dense}ê°œ ì´ìƒ)")

        # 2. ìµœì†Œ Dropout ë ˆì´ì–´ ìˆ˜ ê²€ì‚¬
        min_dropout = requirements.get('min_dropout_layers', 0)
        if min_dropout > 0 and len(dropout_layers) < min_dropout:
            errors.append(f"Dropout ë ˆì´ì–´ ë¶€ì¡± (ì‹¤ì œ: {len(dropout_layers)}, í•„ìš”: {min_dropout}ê°œ ì´ìƒ)")

        # 3. Dropout ë¹„ìœ¨ ê²€ì‚¬
        expected_dropout_rate = requirements.get('dropout_rate')
        if expected_dropout_rate is not None and dropout_layers:
            for i, dropout_layer in enumerate(dropout_layers):
                try:
                    actual_rate = float(dropout_layer.rate)
                    if abs(actual_rate - expected_dropout_rate) > 0.01:
                        errors.append(f"Dropout[{i}] ë¹„ìœ¨ ë¶ˆì¼ì¹˜ (ì‹¤ì œ: {actual_rate}, í•„ìš”: {expected_dropout_rate})")
                except AttributeError:
                    pass  # rate ì†ì„±ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ

        # 4. íˆë“  ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ ê²€ì‚¬
        expected_hidden_activation = requirements.get('hidden_activation')
        if expected_hidden_activation and hidden_dense_layers:
            for i, layer in enumerate(hidden_dense_layers):
                try:
                    # activation í•¨ìˆ˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    if hasattr(layer, 'activation'):
                        activation = layer.activation
                        if hasattr(activation, '__name__'):
                            actual_activation = activation.__name__
                        elif hasattr(activation, 'name'):
                            actual_activation = activation.name
                        else:
                            actual_activation = str(activation)

                        if actual_activation.lower() != expected_hidden_activation.lower():
                            errors.append(f"íˆë“  Dense[{i}] í™œì„±í™” í•¨ìˆ˜ ë¶ˆì¼ì¹˜ (ì‹¤ì œ: {actual_activation}, í•„ìš”: {expected_hidden_activation})")
                except Exception:
                    pass

        # 5. ì¶œë ¥ ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ ê²€ì‚¬
        expected_output_activation = requirements.get('output_activation')
        if expected_output_activation:
            try:
                if hasattr(output_layer, 'activation'):
                    activation = output_layer.activation
                    if hasattr(activation, '__name__'):
                        actual_activation = activation.__name__
                    elif hasattr(activation, 'name'):
                        actual_activation = activation.name
                    else:
                        actual_activation = str(activation)

                    if actual_activation.lower() != expected_output_activation.lower():
                        errors.append(f"ì¶œë ¥ì¸µ í™œì„±í™” í•¨ìˆ˜ ë¶ˆì¼ì¹˜ (ì‹¤ì œ: {actual_activation}, í•„ìš”: {expected_output_activation})")
            except Exception:
                pass

        if errors:
            return False, "ëª¨ë¸ êµ¬ì¡° ì˜¤ë¥˜: " + "; ".join(errors)

        return True, f"ì •ë‹µì…ë‹ˆë‹¤! (Dense: {len(hidden_dense_layers)}ê°œ + ì¶œë ¥ì¸µ, Dropout: {len(dropout_layers)}ê°œ)"

    except Exception as e:
        return False, f"ëª¨ë¸ ê²€ì¦ ì˜¤ë¥˜: {e}"


def detect_answer_type(answer_value: Any) -> Optional[str]:
    """ë³€ìˆ˜ íƒ€ì…ì„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ì±„ì  ìœ í˜• ë°˜í™˜"""
    if answer_value is None:
        return None

    type_name = type(answer_value).__name__
    module_name = type(answer_value).__module__

    # Keras ëª¨ë¸ ê°ì§€
    if 'keras' in module_name.lower() or 'tensorflow' in module_name.lower():
        if 'Sequential' in type_name or 'Model' in type_name or 'Functional' in type_name:
            return 'model_check'

    # matplotlib Figure ê°ì§€
    if 'Figure' in type_name and 'matplotlib' in module_name:
        return 'figure_check'

    # numpy ndarray ê°ì§€ (confusion_matrix)
    if 'ndarray' in type_name:
        return 'confusion_matrix_check'

    # dict íƒ€ì… ê°ì§€ (classification_report ë˜ëŠ” history)
    if isinstance(answer_value, dict):
        # classification_report ê°ì§€ (ë” íŠ¹ì •ì ì¸ ì¡°ê±´ ë¨¼ì € ì²´í¬)
        meta_keys = ['accuracy', 'macro avg', 'weighted avg']
        if all(key in answer_value for key in meta_keys):
            return 'classification_report_check'

        # history.history ê°ì§€ - val_ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ê°€ ìˆìœ¼ë©´
        if any(key.startswith('val_') for key in answer_value.keys()):
            return 'history_check'

    # ìˆ«ì íƒ€ì…
    if isinstance(answer_value, (int, float)):
        return 'exact_number'

    # ë¬¸ìì—´ íƒ€ì…
    if isinstance(answer_value, str):
        return 'exact_string'

    return None


def grade_single_answer(answer_name: str, answer_value: Any, answer_config: Dict) -> Tuple[bool, str]:
    """ë‹¨ì¼ ë‹µì•ˆ ì±„ì 

    typeì´ 'auto'ì´ë©´ ë³€ìˆ˜ íƒ€ì…ì„ ìë™ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ì±„ì  í•¨ìˆ˜ í˜¸ì¶œ
    """
    answer_type = answer_config.get('type', 'auto')

    # auto íƒ€ì…: ë³€ìˆ˜ íƒ€ì…ì„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ì±„ì  ìœ í˜• ê²°ì •
    if answer_type == 'auto':
        detected_type = detect_answer_type(answer_value)
        if detected_type:
            answer_type = detected_type
        else:
            return False, f"ë³€ìˆ˜ íƒ€ì…ì„ ìë™ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (íƒ€ì…: {type(answer_value).__name__})"

    if answer_type == 'exact_number':
        expected = answer_config.get('expected')
        tolerance = answer_config.get('tolerance', 0)
        return check_exact_number(answer_value, expected, tolerance)

    elif answer_type == 'exact_string':
        expected = answer_config.get('expected')
        case_sensitive = answer_config.get('case_sensitive', True)
        return check_exact_string(answer_value, expected, case_sensitive)

    elif answer_type == 'number_range':
        min_val = answer_config.get('min')
        max_val = answer_config.get('max')
        return check_number_range(answer_value, min_val, max_val)

    elif answer_type == 'history_check':
        requirements = answer_config.get('requirements', {})
        return check_history(answer_value, requirements)

    elif answer_type == 'figure_check':
        requirements = answer_config.get('requirements', {})
        return check_figure(answer_value, requirements)

    elif answer_type == 'model_check':
        requirements = answer_config.get('requirements', {})
        return check_keras_model(answer_value, requirements)

    elif answer_type == 'confusion_matrix_check':
        requirements = answer_config.get('requirements', {})
        return check_confusion_matrix(answer_value, requirements)

    elif answer_type == 'classification_report_check':
        requirements = answer_config.get('requirements', {})
        return check_classification_report(answer_value, requirements)

    elif answer_type == 'no_grade':
        return True, "ì±„ì  ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤."

    else:
        return False, f"ì•Œ ìˆ˜ ì—†ëŠ” ì±„ì  ìœ í˜•: {answer_type}"


def grade_answers(globals_dict: Dict, config_path: Optional[str] = None) -> Dict:
    """
    ë©”ì¸ ì±„ì  í•¨ìˆ˜

    Args:
        globals_dict: globals() ë”•ì…”ë„ˆë¦¬ (ë…¸íŠ¸ë¶ì˜ ì „ì—­ ë³€ìˆ˜ë“¤)
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ëª¨ë“ˆê³¼ ê°™ì€ í´ë”ì—ì„œ answer_config.jsonì„ ì°¾ìŒ)

    Returns:
        ì±„ì  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        config = load_config(config_path)
        print(f"ğŸ“ ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config.get('title', 'AICE ì±„ì ')}")
        print("=" * 40)
    except FileNotFoundError as e:
        print(f"ğŸš¨ {e}")
        print(f"ğŸ’¡ aice_ans.pyì™€ answer_config.jsonì„ ê°™ì€ í´ë”ì— ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return {}

    answers_config = config.get('answers', {})
    results = {}
    correct_count = 0
    total_count = 0

    # ë‹µì•ˆ ì´ë¦„ ì •ë ¬ (ë‹µì•ˆ01, ë‹µì•ˆ02, ... ìˆœì„œë¡œ)
    def sort_key(name):
        # ë‹µì•ˆ01, ë‹µì•ˆ02, ë‹µì•ˆ08_1, ë‹µì•ˆ08_2 ë“±ì„ ì˜¬ë°”ë¥´ê²Œ ì •ë ¬
        import re
        match = re.match(r'ë‹µì•ˆ(\d+)(?:_(\d+))?', name)
        if match:
            main_num = int(match.group(1))
            sub_num = int(match.group(2)) if match.group(2) else 0
            return (main_num, sub_num)
        return (999, 0)

    sorted_answer_names = sorted(answers_config.keys(), key=sort_key)

    for answer_name in sorted_answer_names:
        answer_config = answers_config[answer_name]

        # ê¸€ë¡œë²Œ ë³€ìˆ˜ì—ì„œ ë‹µì•ˆ ê°€ì ¸ì˜¤ê¸°
        if answer_name not in globals_dict:
            print(f"âš ï¸  {answer_name}: ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("-" * 20)
            results[answer_name] = (False, "ë³€ìˆ˜ ë¯¸ì •ì˜")
            total_count += 1
            continue

        answer_value = globals_dict[answer_name]

        # ì±„ì 
        is_correct, message = grade_single_answer(answer_name, answer_value, answer_config)
        results[answer_name] = (is_correct, message)

        # ê²°ê³¼ ì¶œë ¥
        if answer_config.get('type') == 'no_grade':
            print(f"â­ï¸  {answer_name}: {message}")
        elif is_correct:
            print(f"âœ… {answer_name}: {message}")
            correct_count += 1
        else:
            print(f"âŒ {answer_name}: {message}")

        if answer_config.get('type') != 'no_grade':
            total_count += 1

        print("-" * 20)

    # ìµœì¢… ê²°ê³¼
    print(f"\nğŸ“Š ì±„ì  ê²°ê³¼: {correct_count}/{total_count} ì •ë‹µ")
    if total_count > 0:
        score = (correct_count / total_count) * 100
        print(f"ğŸ“ˆ ì ìˆ˜: {score:.1f}%")

    return results


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    print("AICE ì±„ì  ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì‚¬ìš©ë²•: aice_ans.grade_answers(globals())")
